{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21073ccc",
   "metadata": {
    "papermill": {
     "duration": 0.00479,
     "end_time": "2025-01-13T22:01:44.601011",
     "exception": false,
     "start_time": "2025-01-13T22:01:44.596221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# CZII: Convert czii10411 to Numpy arrays and annotations\n",
    "\n",
    "[Forked from here](https://www.kaggle.com/code/sersasj/czii-making-datasets-for-yolo-synthetic-data)\n",
    "\n",
    "My goal,  to denoise and modify the format and file structure to a simpler thing to work with, saving as .npy arrays for the volume, json files for each of the particle types.\n",
    "\n",
    "So for the denoised volumes: Volumes/TS____.npy\n",
    "For the annotations: Annotations/TS____/apo-ferritin.json   beta-amylase.json etc  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2f684",
   "metadata": {
    "_cell_guid": "736bdd25-fc27-4ced-bdcb-3e17c2eaa80f",
    "_uuid": "2e538122-a0c3-4dab-963f-ca3fec61a155",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.003678,
     "end_time": "2025-01-13T22:01:44.608809",
     "exception": false,
     "start_time": "2025-01-13T22:01:44.605131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020574fa",
   "metadata": {
    "_cell_guid": "51687ee2-978f-4364-aed1-f4a8051735db",
    "_uuid": "c47f4213-e8e9-4daa-8f6e-2534f2330d9d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:01:44.619002Z",
     "iopub.status.busy": "2025-01-13T22:01:44.617978Z",
     "iopub.status.idle": "2025-01-13T22:01:59.949602Z",
     "shell.execute_reply": "2025-01-13T22:01:59.948189Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.340206,
     "end_time": "2025-01-13T22:01:59.952820",
     "exception": false,
     "start_time": "2025-01-13T22:01:44.612614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zarr\r\n",
      "  Downloading zarr-2.18.3-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\r\n",
      "Collecting asciitree (from zarr)\r\n",
      "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from zarr) (1.26.4)\r\n",
      "Collecting numcodecs>=0.10.0 (from zarr)\r\n",
      "  Downloading numcodecs-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr) (0.19)\r\n",
      "Downloading zarr-2.18.3-py3-none-any.whl (210 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numcodecs-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: asciitree\r\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=aac3fa8e3970d999c08d963e0dd939974d60715094a04b36dc4e9cd4c1f07c45\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\r\n",
      "Successfully built asciitree\r\n",
      "Installing collected packages: asciitree, numcodecs, zarr\r\n",
      "Successfully installed asciitree-0.3.3 numcodecs-0.13.1 zarr-2.18.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install zarr opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892921d2",
   "metadata": {
    "_cell_guid": "a5452423-001e-4d09-9e1b-2fe60d390fa9",
    "_uuid": "e19a24b5-9a8e-4758-9466-dc82945251d5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:01:59.972392Z",
     "iopub.status.busy": "2025-01-13T22:01:59.971957Z",
     "iopub.status.idle": "2025-01-13T22:02:02.196164Z",
     "shell.execute_reply": "2025-01-13T22:02:02.195042Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.236844,
     "end_time": "2025-01-13T22:02:02.198568",
     "exception": false,
     "start_time": "2025-01-13T22:01:59.961724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "import glob, os\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb27f2fa",
   "metadata": {
    "_cell_guid": "7f87b90b-b803-44fa-817b-54ef06b8cc02",
    "_uuid": "dfdbf477-3136-4e21-b984-169ebc610cda",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.212323Z",
     "iopub.status.busy": "2025-01-13T22:02:02.211640Z",
     "iopub.status.idle": "2025-01-13T22:02:02.230820Z",
     "shell.execute_reply": "2025-01-13T22:02:02.229702Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028952,
     "end_time": "2025-01-13T22:02:02.233059",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.204107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/czii10441/10441/TS_0', '/kaggle/input/czii10441/10441/TS_1', '/kaggle/input/czii10441/10441/TS_10', '/kaggle/input/czii10441/10441/TS_11', '/kaggle/input/czii10441/10441/TS_12', '/kaggle/input/czii10441/10441/TS_13', '/kaggle/input/czii10441/10441/TS_14', '/kaggle/input/czii10441/10441/TS_15', '/kaggle/input/czii10441/10441/TS_16', '/kaggle/input/czii10441/10441/TS_17', '/kaggle/input/czii10441/10441/TS_18', '/kaggle/input/czii10441/10441/TS_19', '/kaggle/input/czii10441/10441/TS_2', '/kaggle/input/czii10441/10441/TS_20', '/kaggle/input/czii10441/10441/TS_21', '/kaggle/input/czii10441/10441/TS_22', '/kaggle/input/czii10441/10441/TS_23', '/kaggle/input/czii10441/10441/TS_24', '/kaggle/input/czii10441/10441/TS_25', '/kaggle/input/czii10441/10441/TS_26', '/kaggle/input/czii10441/10441/TS_3', '/kaggle/input/czii10441/10441/TS_4', '/kaggle/input/czii10441/10441/TS_5', '/kaggle/input/czii10441/10441/TS_6', '/kaggle/input/czii10441/10441/TS_7', '/kaggle/input/czii10441/10441/TS_8', '/kaggle/input/czii10441/10441/TS_9']\n",
      "Runs: {0: 'TS_0', 1: 'TS_1', 2: 'TS_10', 3: 'TS_11', 4: 'TS_12', 5: 'TS_13', 6: 'TS_14', 7: 'TS_15', 8: 'TS_16', 9: 'TS_17', 10: 'TS_18', 11: 'TS_19', 12: 'TS_2', 13: 'TS_20', 14: 'TS_21', 15: 'TS_22', 16: 'TS_23', 17: 'TS_24', 18: 'TS_25', 19: 'TS_26', 20: 'TS_3', 21: 'TS_4', 22: 'TS_5', 23: 'TS_6', 24: 'TS_7', 25: 'TS_8', 26: 'TS_9'}\n"
     ]
    }
   ],
   "source": [
    "synthetic_runs = sorted(glob.glob('/kaggle/input/czii10441/10441/T*'))\n",
    "print(synthetic_runs)\n",
    "runs = [os.path.basename(x) for x in synthetic_runs]\n",
    "i2r_dict = {i: r for i, r in zip(range(len(runs)), runs)}\n",
    "r2t_dict = {r: i for i, r in zip(range(len(runs)), runs)}\n",
    "print(\"Runs:\", i2r_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce30b3e",
   "metadata": {
    "_cell_guid": "77ca1180-b9b3-4c11-9b95-818e1625529a",
    "_uuid": "2aab94e2-68df-4cf9-b2f6-2fe18b3d6ee0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004853,
     "end_time": "2025-01-13T22:02:02.243085",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.238232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Normalize Function\n",
    "Normalize the image to a value between 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0840cbb7",
   "metadata": {
    "_cell_guid": "054c7292-d91d-41f6-b487-b0ba5663b11c",
    "_uuid": "3ba10d74-2f36-497d-a2a9-b733d622cfa9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.255109Z",
     "iopub.status.busy": "2025-01-13T22:02:02.254628Z",
     "iopub.status.idle": "2025-01-13T22:02:02.260763Z",
     "shell.execute_reply": "2025-01-13T22:02:02.259609Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014639,
     "end_time": "2025-01-13T22:02:02.262984",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.248345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_8bit(x):\n",
    "    lower, upper = np.percentile(x, (0.5, 99.5))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = (x - x.min()) / (x.max() - x.min() + 1e-12) * 255\n",
    "    return x.round().astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f210e9",
   "metadata": {
    "_cell_guid": "604020c8-ee33-40b7-b4c4-7c856afbc050",
    "_uuid": "84679000-637f-435a-8533-5200f48461a4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004876,
     "end_time": "2025-01-13T22:02:02.273093",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.268217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Information about Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa2893a",
   "metadata": {
    "_cell_guid": "bdc150d8-88f7-47e7-96e0-a07d0f0333ea",
    "_uuid": "88e9a2c2-4b0e-47e0-a6a8-7d808745d834",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.285477Z",
     "iopub.status.busy": "2025-01-13T22:02:02.285066Z",
     "iopub.status.idle": "2025-01-13T22:02:02.291391Z",
     "shell.execute_reply": "2025-01-13T22:02:02.290320Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014814,
     "end_time": "2025-01-13T22:02:02.293545",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.278731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2i_dict = {\n",
    "    'apo-ferritin': 0,\n",
    "    'beta-amylase': 1,\n",
    "    'beta-galactosidase': 2,\n",
    "    'ribosome': 3,\n",
    "    'thyroglobulin': 4,\n",
    "    'virus-like-particle': 5\n",
    "}\n",
    "\n",
    "i2p = {v: k for k, v in p2i_dict.items()}\n",
    "\n",
    "particle_radius = {\n",
    "    'apo-ferritin': 60,\n",
    "    'beta-amylase': 65,\n",
    "    'beta-galactosidase': 90,\n",
    "    'ribosome': 150,\n",
    "    'thyroglobulin': 130,\n",
    "    'virus-like-particle': 135,\n",
    "}\n",
    "\n",
    "particle_names = ['apo-ferritin', 'beta-amylase', 'beta-galactosidase', 'ribosome', 'thyroglobulin', 'virus-like-particle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90e7b45",
   "metadata": {
    "_cell_guid": "a95de667-0335-427e-a4c4-62d6c7c47033",
    "_uuid": "94713e56-ee02-41e9-8e75-bb37a835d664",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.307184Z",
     "iopub.status.busy": "2025-01-13T22:02:02.306066Z",
     "iopub.status.idle": "2025-01-13T22:02:02.312494Z",
     "shell.execute_reply": "2025-01-13T22:02:02.311483Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015167,
     "end_time": "2025-01-13T22:02:02.314564",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.299397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def denoise_tomogram(tomogram, method='gaussian', **kwargs):\n",
    "    \"\"\"\n",
    "    Apply denoising to a tomogram.\n",
    "\n",
    "    Parameters:\n",
    "        tomogram (np.ndarray): The input tomogram to denoise.\n",
    "        method (str): The denoising method ('gaussian' or 'median').\n",
    "        kwargs: Parameters for the respective method.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The denoised tomogram.\n",
    "    \"\"\"\n",
    "    if method == 'gaussian':\n",
    "        return gaussian_filter(tomogram, sigma=kwargs.get('sigma', 1))\n",
    "    elif method == 'median':\n",
    "        return median_filter(tomogram, size=kwargs.get('size', 3))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported denoising method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6605a4",
   "metadata": {
    "_cell_guid": "0e2411db-b47b-4d5d-916d-086b7401280f",
    "_uuid": "4a9fc3a6-0f84-48eb-8c88-ae1d06b1b748",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.326334Z",
     "iopub.status.busy": "2025-01-13T22:02:02.325923Z",
     "iopub.status.idle": "2025-01-13T22:02:02.330745Z",
     "shell.execute_reply": "2025-01-13T22:02:02.329755Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013093,
     "end_time": "2025-01-13T22:02:02.332765",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.319672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_map = {\n",
    "    'apo-ferritin': 'ferritin_complex',\n",
    "    'beta-amylase': 'beta_amylase',\n",
    "    'beta-galactosidase': 'beta_galactosidase',\n",
    "    'ribosome': 'cytosolic_ribosome',\n",
    "    'thyroglobulin': 'thyroglobulin',\n",
    "    'virus-like-particle': 'pp7_vlp',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4960c747",
   "metadata": {
    "_cell_guid": "8f7195d1-60f2-4f19-993f-d11f0439c282",
    "_uuid": "4858d56f-d154-45b8-8b8e-18b1bc566ba2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.344642Z",
     "iopub.status.busy": "2025-01-13T22:02:02.344294Z",
     "iopub.status.idle": "2025-01-13T22:02:02.357090Z",
     "shell.execute_reply": "2025-01-13T22:02:02.356047Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021616,
     "end_time": "2025-01-13T22:02:02.359580",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.337964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ndjson_to_json(ndjson_path):\n",
    "    if not os.path.isfile(ndjson_path):\n",
    "        raise FileNotFoundError(f\"The file {ndjson_path} does not exist.\")\n",
    "\n",
    "    data = []\n",
    "    try:\n",
    "        with open(ndjson_path, 'r', encoding='utf-8') as ndjson_file:\n",
    "            for line_number, line in enumerate(ndjson_file, start=1):\n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line:  \n",
    "                    try:\n",
    "                        json_object = json.loads(stripped_line)\n",
    "                        data.append(json_object)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        raise json.JSONDecodeError(\n",
    "                            f\"Error decoding JSON on line {line_number}: {e.msg}\",\n",
    "                            e.doc,\n",
    "                            e.pos\n",
    "                        )\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "    wrapped_data = {\"points\": data}  #to match the json structure of our real samples\n",
    "\n",
    "    return wrapped_data\n",
    "\n",
    "def make_denoised_vol(run_name):\n",
    "\n",
    "    # Path to the volume  \n",
    "    vol_path = glob.glob(f'/kaggle/input/czii10441/10441/{run_name}/**/Tomograms/**/*.zarr', recursive=True)\n",
    "    if not vol_path:\n",
    "        print(f\"No volume found for run {run_name} in synthetic data.\")\n",
    "        return\n",
    "    vol_path = vol_path[0]\n",
    "    \n",
    "    print(f\"Volume path: {vol_path}\")\n",
    "    if not os.path.exists(vol_path):\n",
    "        print(f\"Volume file not found: {vol_path}\")\n",
    "        return\n",
    "\n",
    "    # Read the volume\n",
    "    vol = zarr.open(vol_path, mode='r')\n",
    "    vol = vol[0]\n",
    "    vol = denoise_tomogram(np.array(vol)[:184], method='gaussian', sigma=1)  # Apply denoise\n",
    "    vol_2 = convert_to_8bit(vol)\n",
    "\n",
    "    vol_path = Path(f'/kaggle/working/Volumes/{run_name}.npy')\n",
    "    np.save(vol_path, vol_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Process each particle type\n",
    "    os.makedirs(f'Annotations/{run_name}', exist_ok=True)\n",
    "                  \n",
    "    for p, particle in enumerate(particle_names):\n",
    "        \n",
    "        particle_name_in_file = name_map.get(particle)\n",
    "        if not particle_name_in_file:\n",
    "            print(f\"Particle name mapping not found for: {particle}\")\n",
    "            continue\n",
    "        \n",
    "        ndjson_each_particle = glob.glob(f'/kaggle/input/czii10441/10441/{run_name}/**/Annotations/**/*.ndjson', recursive=True)\n",
    "        if not ndjson_each_particle:\n",
    "            print(f\"No NDJSON files found for particle: {particle} in run: {run_name}\")\n",
    "            continue\n",
    "        \n",
    "        filtered_ndjson_files = [f for f in ndjson_each_particle if particle_name_in_file in f]\n",
    "        if not filtered_ndjson_files:\n",
    "            print(f\"No NDJSON files match the particle: {particle} for run: {run_name}\")\n",
    "            continue\n",
    "        \n",
    "        json_each_particle = ndjson_to_json(filtered_ndjson_files[0])\n",
    "\n",
    "        json_file_path = Path(f'Annotations/{run_name}/{particle}.json')\n",
    "        with json_file_path.open(\"w\") as json_file:\n",
    "            json.dump(json_each_particle, json_file, indent=4)\n",
    "        \n",
    "        \n",
    "        #df = pd.DataFrame(json_each_particle)\n",
    "\n",
    "        #if  'location' not in df.columns:\n",
    "        #    print(f\"'{column_name}' column not found in DataFrame for particle: {particle}\")\n",
    "        #    continue\n",
    "        \n",
    "        #normalized_data = pd.json_normalize(df['location'])\n",
    "        #df[['x', 'y', 'z']] = normalized_data * 10.012\n",
    "        #df.dropna(subset=[\"x\", \"y\", \"z\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542a5b4",
   "metadata": {
    "_cell_guid": "fa61e5b4-d751-43f3-8f6e-dfaaebb9eefe",
    "_uuid": "653ce678-ab5d-4abf-bc17-6007187deea1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004808,
     "end_time": "2025-01-13T22:02:02.369626",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.364818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864971cc",
   "metadata": {
    "_cell_guid": "709c669d-e88a-4429-a894-66497b52f0df",
    "_uuid": "0987649d-3e79-4c24-85bc-df66315886b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.381574Z",
     "iopub.status.busy": "2025-01-13T22:02:02.381175Z",
     "iopub.status.idle": "2025-01-13T22:02:02.386292Z",
     "shell.execute_reply": "2025-01-13T22:02:02.385413Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013687,
     "end_time": "2025-01-13T22:02:02.388490",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.374803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"Volumes\", exist_ok=True)\n",
    "os.makedirs(\"Annotations\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeab80d",
   "metadata": {
    "_cell_guid": "aae5b85a-0e04-4024-b6b8-11f2c4be72b2",
    "_uuid": "3dfff00e-14bd-406e-a7b8-8f3bcde4268b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.004694,
     "end_time": "2025-01-13T22:02:02.398340",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.393646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4e47a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T22:02:02.410099Z",
     "iopub.status.busy": "2025-01-13T22:02:02.409232Z",
     "iopub.status.idle": "2025-01-13T22:03:32.191551Z",
     "shell.execute_reply": "2025-01-13T22:03:32.190105Z"
    },
    "papermill": {
     "duration": 89.790864,
     "end_time": "2025-01-13T22:03:32.194060",
     "exception": false,
     "start_time": "2025-01-13T22:02:02.403196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Runs: 100%|██████████| 27/27 [01:05<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "def parallel_denoising(runs, n_jobs=-1):\n",
    "    \"\"\"Runs make_denoised_vol in parallel for a list of runs.\"\"\"\n",
    "    Parallel(n_jobs=n_jobs)(\n",
    "        delayed(make_denoised_vol)(run) for run in tqdm(runs, desc=\"Processing Runs\")\n",
    "    )\n",
    "\n",
    "parallel_denoising(runs)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10033515,
     "sourceId": 84969,
     "sourceType": "competition"
    },
    {
     "datasetId": 6083037,
     "sourceId": 9902245,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 113.572248,
   "end_time": "2025-01-13T22:03:34.820432",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-13T22:01:41.248184",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
